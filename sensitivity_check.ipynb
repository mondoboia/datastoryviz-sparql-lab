{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI1COQYneXlz"
      },
      "source": [
        "## SPARQL proficiency\n",
        "\n",
        "To assess the robustness of the SPARQL proficiency metric, we recompute proficiency scores using four alternative weighting schemes, including equal-weight and correctness-dominant configurations, while keeping all sub-metrics constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kougn2tNX0vj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def compute_sparql_proficiency_sensitivity_check(\n",
        "    row,\n",
        "    weight_wc,\n",
        "    weight_fed,\n",
        "    weight_feat,\n",
        "    weight_diversity\n",
        "):\n",
        "    return (\n",
        "        row['correct_normalized'] * weight_wc +\n",
        "        row['federated_bonus'] * weight_fed +\n",
        "        row['normalized_sparql_feature_metric'] * weight_feat +\n",
        "        row['diversity_metric'] * weight_diversity\n",
        "    )\n",
        "\n",
        "weighting_schemes = {\n",
        "    \"original\": {\n",
        "        \"weight_wc\": 0.10,\n",
        "        \"weight_fed\": 0.10,\n",
        "        \"weight_feat\": 0.40,\n",
        "        \"weight_diversity\": 0.40\n",
        "    },\n",
        "    \"equal\": {\n",
        "        \"weight_wc\": 0.25,\n",
        "        \"weight_fed\": 0.25,\n",
        "        \"weight_feat\": 0.25,\n",
        "        \"weight_diversity\": 0.25\n",
        "    },\n",
        "    \"correctness_heavy\": {\n",
        "        \"weight_wc\": 0.40,\n",
        "        \"weight_fed\": 0.20,\n",
        "        \"weight_feat\": 0.20,\n",
        "        \"weight_diversity\": 0.20\n",
        "    },\n",
        "    \"feature_heavy\": {\n",
        "        \"weight_wc\": 0.10,\n",
        "        \"weight_fed\": 0.10,\n",
        "        \"weight_feat\": 0.50,\n",
        "        \"weight_diversity\": 0.30\n",
        "    }\n",
        "}\n",
        "\n",
        "df_proficiency_final = pd.read_csv(\n",
        "    \"outputs/sparql_proficiency_stage_three.csv\",\n",
        "    index_col=0\n",
        ")\n",
        "\n",
        "for scheme_name, weights in weighting_schemes.items():\n",
        "    df_proficiency_final[f'sparql_proficiency_{scheme_name}'] = (\n",
        "        df_proficiency_final.apply(\n",
        "            compute_sparql_proficiency_sensitivity_check,\n",
        "            axis=1,\n",
        "            **weights\n",
        "        )\n",
        "    )\n",
        "\n",
        "df_proficiency_final.to_csv(\"outputs/sparql_proficiency_sensitivity.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weFhucCSYera"
      },
      "source": [
        "# Readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rXUgPkwYgII",
        "outputId": "7a66e317-1b05-41c1-cf5b-2736707f2512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    weighting_scheme  pearson_r  pearson_p  spearman_r  spearman_p\n",
            "0           original     -0.215      0.143      -0.291       0.045\n",
            "1              equal     -0.153      0.299      -0.282       0.052\n",
            "2  correctness_heavy     -0.143      0.331      -0.253       0.083\n",
            "3      feature_heavy     -0.217      0.139      -0.297       0.041\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Load data\n",
        "df_readability = pd.read_csv('outputs/readability_scores.csv', index_col=0)\n",
        "df_sparql = pd.read_csv('outputs/sparql_proficiency_sensitivity.csv', index_col=0)\n",
        "df_alternation = pd.read_csv('outputs/alternation_scores.csv', index_col=0)\n",
        "\n",
        "# Merge datasets\n",
        "df_temp = pd.merge(\n",
        "    df_readability[['story_id', 'flesch_reading_ease', 'normalized_readability']],\n",
        "    df_sparql,\n",
        "    on='story_id',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "df_combined = pd.merge(\n",
        "    df_temp,\n",
        "    df_alternation[['story_id', 'alternation_score']],\n",
        "    on='story_id',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Filter out stories without text\n",
        "story_no_text = ['SXefpzf4', 'EzsIH_Et', '6yGct8pP']\n",
        "df_filtered = df_combined[~df_combined['story_id'].isin(story_no_text)]\n",
        "\n",
        "# Identify all SPARQL proficiency variants\n",
        "sparql_columns = [\n",
        "    col for col in df_filtered.columns\n",
        "    if col.startswith('sparql_proficiency_')\n",
        "]\n",
        "\n",
        "# Run sensitivity analysis\n",
        "results = []\n",
        "\n",
        "for col in sparql_columns:\n",
        "    pearson_corr, pearson_p = pearsonr(\n",
        "        df_filtered['flesch_reading_ease'],\n",
        "        df_filtered[col]\n",
        "    )\n",
        "\n",
        "    spearman_corr, spearman_p = spearmanr(\n",
        "        df_filtered['flesch_reading_ease'],\n",
        "        df_filtered[col]\n",
        "    )\n",
        "\n",
        "    results.append({\n",
        "        'weighting_scheme': col.replace('sparql_proficiency_', ''),\n",
        "        'pearson_r': pearson_corr,\n",
        "        'pearson_p': pearson_p,\n",
        "        'spearman_r': spearman_corr,\n",
        "        'spearman_p': spearman_p\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame for easy inspection / export\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "print(df_results.round(3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAvKklagbgDP"
      },
      "source": [
        "**Pattern**\n",
        "\n",
        "Direction is stable across all weighting schemes: While SPARQL proficiency increases, readability decreases.\n",
        "\n",
        "Effect sizes are small-to-moderate (|ρ| ≈ 0.25–0.30)\n",
        "\n",
        "Significance is marginal and scheme-dependent (significant for original and feature-heavy (Spearman), trends but not significant elsewhere)\n",
        "\n",
        "**Summary** The relationship does not depend on a specific weighting. But it is weak and exploratory. In conclusion, readability is influenced by many factors beyond query proficiency, which actually supports our theoretical claim that technical sophistication can trade off with surface readability — but not strongly or deterministically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOj9w1DvZ94P"
      },
      "source": [
        "## Coherence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN1GgdBiZ_EA",
        "outputId": "65678844-2d12-44d2-d43c-ff4f6eba8c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    weighting_scheme  pearson_r  pearson_p  spearman_r  spearman_p\n",
            "0           original      0.200      0.172       0.438       0.002\n",
            "1              equal      0.135      0.361       0.429       0.002\n",
            "2  correctness_heavy      0.128      0.387       0.373       0.009\n",
            "3      feature_heavy      0.197      0.180       0.428       0.002\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Load data\n",
        "df_coherence = pd.read_csv('outputs/coherence_scores.csv', index_col=0)\n",
        "df_sparql = pd.read_csv('outputs/sparql_proficiency_sensitivity.csv', index_col=0)\n",
        "df_alternation = pd.read_csv('outputs/alternation_scores.csv', index_col=0)\n",
        "\n",
        "# Merge datasets\n",
        "df_temp = pd.merge(\n",
        "    df_coherence[['story_id', 'coherence_score']],\n",
        "    df_sparql,\n",
        "    on='story_id',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "df_combined = pd.merge(\n",
        "    df_temp,\n",
        "    df_alternation[['story_id', 'alternation_score']],\n",
        "    on='story_id',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Filter out stories without text\n",
        "story_no_text = ['SXefpzf4', 'EzsIH_Et', '6yGct8pP']\n",
        "df_filtered = df_combined[~df_combined['story_id'].isin(story_no_text)]\n",
        "\n",
        "# Identify SPARQL proficiency variants\n",
        "sparql_columns = [\n",
        "    col for col in df_filtered.columns\n",
        "    if col.startswith('sparql_proficiency_')\n",
        "]\n",
        "\n",
        "# Run sensitivity analysis\n",
        "results = []\n",
        "\n",
        "for col in sparql_columns:\n",
        "    pearson_corr, pearson_p = pearsonr(\n",
        "        df_filtered['coherence_score'],\n",
        "        df_filtered[col]\n",
        "    )\n",
        "\n",
        "    spearman_corr, spearman_p = spearmanr(\n",
        "        df_filtered['coherence_score'],\n",
        "        df_filtered[col]\n",
        "    )\n",
        "\n",
        "    results.append({\n",
        "        'weighting_scheme': col.replace('sparql_proficiency_', ''),\n",
        "        'pearson_r': pearson_corr,\n",
        "        'pearson_p': pearson_p,\n",
        "        'spearman_r': spearman_corr,\n",
        "        'spearman_p': spearman_p\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "print(df_results.round(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrAp3XCNcEkY"
      },
      "source": [
        "**Pattern** Spearman correlations are strong and highly stable\n",
        "\n",
        "ρ ≈ 0.37–0.44\n",
        "\n",
        "p ≤ 0.01 across all schemes\n",
        "\n",
        "Pearson is weaker and non-significant (fine; coherence is bounded/ordinal)\n",
        "\n",
        "**Summary** The SPARQL–coherence relationship is monotonic, not linear. It is robust to all weighting schemes and it is not an artifact of how proficiency is operationalized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VbSDq8Oagc0"
      },
      "source": [
        "## Alternation (good structure)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mMAScuhai15",
        "outputId": "05e155c4-a6dd-42fe-ffa9-9167c0e2ff42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    weighting_scheme  pearson_r  pearson_p  spearman_r  spearman_p\n",
            "0           original      0.221      0.131       0.080       0.589\n",
            "1              equal      0.222      0.130       0.016       0.914\n",
            "2  correctness_heavy      0.148      0.315      -0.001       0.997\n",
            "3      feature_heavy      0.229      0.118       0.092       0.536\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Load data\n",
        "df_alternation = pd.read_csv('outputs/alternation_scores.csv', index_col=0)\n",
        "df_sparql = pd.read_csv('outputs/sparql_proficiency_sensitivity.csv', index_col=0)\n",
        "\n",
        "# Merge datasets\n",
        "df_combined = pd.merge(\n",
        "    df_alternation[['story_id', 'alternation_score']],\n",
        "    df_sparql,\n",
        "    on='story_id',\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Filter out stories without text\n",
        "story_no_text = ['SXefpzf4', 'EzsIH_Et', '6yGct8pP']\n",
        "df_filtered = df_combined[~df_combined['story_id'].isin(story_no_text)]\n",
        "\n",
        "# Identify SPARQL proficiency variants\n",
        "sparql_columns = [\n",
        "    col for col in df_filtered.columns\n",
        "    if col.startswith('sparql_proficiency_')\n",
        "]\n",
        "\n",
        "# Run sensitivity analysis\n",
        "results = []\n",
        "\n",
        "for col in sparql_columns:\n",
        "    x = np.array(df_filtered['alternation_score'])\n",
        "    y = np.array(df_filtered[col])\n",
        "\n",
        "    pearson_corr, pearson_p = pearsonr(x, y)\n",
        "    spearman_corr, spearman_p = spearmanr(x, y)\n",
        "\n",
        "    results.append({\n",
        "        'weighting_scheme': col.replace('sparql_proficiency_', ''),\n",
        "        'pearson_r': pearson_corr,\n",
        "        'pearson_p': pearson_p,\n",
        "        'spearman_r': spearman_corr,\n",
        "        'spearman_p': spearman_p\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "print(df_results.round(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNxN9PRFcZvG"
      },
      "source": [
        "**Pattern** Pearson: small positive correlations (≈ 0.15–0.23), non-significant. Spearman: near zero, unstable, non-significant\n",
        "\n",
        "**Summary** No robust association between SPARQL proficiency and alternation. Any apparent relationship in the original analysis was likely weak or sample-sensitive. Alternation is probably a stylistic or pedagogical choice, not a skill proxy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_KT588-y4wl"
      },
      "source": [
        "## FDR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoxrOepDy56G",
        "outputId": "727cde6b-bf45-42fd-9e90-4d9fd6a31db3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.0675, 0.006 , 0.589 ])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "p_readability, p_coherence, p_alternation = 0.045, 0.002, 0.589\n",
        "\n",
        "pvals = [p_readability, p_coherence, p_alternation]\n",
        "_, pvals_fdr, _, _ = multipletests(pvals, method='fdr_bh')\n",
        "\n",
        "pvals_fdr"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
